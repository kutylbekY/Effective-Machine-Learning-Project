{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet101_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image saved at: output2\\image_2023-07-19_17-00-48.png\n",
      "Processed image saved at: output2\\photo1689764388.jpeg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models.segmentation as segmentation\n",
    "from torchvision.models.segmentation import deeplabv3_resnet101\n",
    "from scipy.ndimage import binary_dilation, binary_erosion, binary_fill_holes\n",
    "\n",
    "def load_model(device='cuda'):\n",
    "    # Using U-Net instead of DeepLabV3\n",
    "    model = deeplabv3_resnet101(weights=True)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def process_image(image_path, model, device='cuda'):\n",
    "    # Load and preprocess the input image\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    # Define the target image size for faster processing\n",
    "    target_size = 768\n",
    "\n",
    "    # Resize the image for faster processing\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((target_size, target_size)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    input_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    # Use the segmentation model to get the segmentation mask\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)['out'][0]\n",
    "        output_predictions = output.argmax(0).cpu().numpy()\n",
    "\n",
    "    # Upscale the output mask to the original size\n",
    "    upscale_transform = transforms.Resize(img.size)\n",
    "    output_mask = upscale_transform(Image.fromarray(output_predictions.astype('uint8')))\n",
    "\n",
    "    # Convert the Image object to a NumPy array\n",
    "    output_mask_np = np.array(output_mask)\n",
    "\n",
    "    # Resize the output mask to match the original image size\n",
    "    output_mask_resized = Image.fromarray(output_mask_np).resize(img.size)\n",
    "\n",
    "    # Create a binary mask for the object\n",
    "    object_mask_np = torch.tensor(np.array(output_mask_resized) == 15)  # Class 15 represents the object of interest\n",
    "\n",
    "    # Create a new binary mask containing only the top pixels of the object\n",
    "    top_pixels_mask = torch.zeros_like(object_mask_np)\n",
    "    top_pixels_mask[0:100, :] = object_mask_np[0:100, :]  # Adjust the top region height as needed\n",
    "\n",
    "    # Perform dilation/erosion on the binary mask to enhance the top pixels of the object\n",
    "    top_pixels_mask_eroded = binary_erosion(top_pixels_mask.numpy(), structure=np.ones((5, 5)))\n",
    "\n",
    "    # Combine the original object mask with the eroded top pixels mask\n",
    "    object_mask_eroded = object_mask_np.clone()\n",
    "    object_mask_eroded[0:50, :] = torch.tensor(top_pixels_mask_eroded[0:50, :])\n",
    "\n",
    "    # Create a new image with a black background and the object from the original image\n",
    "    new_image = Image.new(\"RGB\", img.size, color=(0, 0, 0))\n",
    "    object_pixels = img.copy().convert(\"RGBA\").crop((0, 0, img.size[0], img.size[1]))\n",
    "    new_image.paste(object_pixels, (0, 0), mask=Image.fromarray(object_mask_eroded.numpy()))\n",
    "\n",
    "    return new_image\n",
    "\n",
    "def process_images_in_folder(input_folder, output_folder, model, device='cuda'):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Get a list of all image files in the input folder\n",
    "    image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif'))]\n",
    "\n",
    "    for image_file in image_files:\n",
    "        input_image_path = os.path.join(input_folder, image_file)\n",
    "        output_image = process_image(input_image_path, model, device)\n",
    "\n",
    "        # Save the processed image in the output folder with the same filename\n",
    "        output_image_path = os.path.join(output_folder, image_file)\n",
    "        output_image.save(output_image_path)\n",
    "\n",
    "        print(\"Processed image saved at:\", output_image_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if GPU is available and set device accordingly\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    # Load the pre-trained model\n",
    "    model = load_model(device)\n",
    "\n",
    "    # Set input and output folder paths\n",
    "    input_folder = \"input2\"\n",
    "    output_folder = \"output2\"\n",
    "\n",
    "    # Process all images in the input folder and save the processed images to the output folder\n",
    "    process_images_in_folder(input_folder, output_folder, model, device)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
